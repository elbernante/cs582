{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, concatenate, Concatenate, Conv2D, MaxPooling2D, AveragePooling2D, Conv2DTranspose\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "from lib.stats_tools import dice_coef, dice_coef_loss, f1_score, f2_score, f05_score\n",
    "from lib.callbacks import TrainMonitor\n",
    "from lib.util import image_augment, get_train_val_sets\n",
    "\n",
    "from config import *\n",
    "\n",
    "K.set_image_data_format('channels_last')  # TF dimension ordering in this code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Inception_B(filter_size, activation='relu', padding='valid'):\n",
    "    def _layer(input_tensor):\n",
    "        f1 = filter_size // 4\n",
    "        tower_1 = Conv2D(f1, (1, 1), activation=activation, padding=padding)(input_tensor)\n",
    "        tower_1 = Conv2D(f1, (1, 7), activation=activation, padding=padding)(tower_1)\n",
    "        tower_1 = Conv2D(f1, (7, 1), activation=activation, padding=padding)(tower_1)\n",
    "        tower_1 = Conv2D(f1, (1, 7), activation=activation, padding=padding)(tower_1)\n",
    "        tower_1 = Conv2D(f1, (7, 1), activation=activation, padding=padding)(tower_1)\n",
    "        \n",
    "        tower_2 = Conv2D(f1, (1, 1), activation=activation, padding=padding)(input_tensor)\n",
    "        tower_2 = Conv2D(f1, (1, 7), activation=activation, padding=padding)(tower_2)\n",
    "        tower_2 = Conv2D(f1, (7, 1), activation=activation, padding=padding)(tower_2)\n",
    "        \n",
    "        tower_3 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(input_tensor)\n",
    "        tower_3 = Conv2D(f1, (1, 1), activation=activation, padding=padding)(tower_3)\n",
    "        \n",
    "        tower_4 = Conv2D(f1, (1, 1), activation=activation, padding=padding)(input_tensor)\n",
    "        \n",
    "        return Concatenate(axis=-1)([tower_1, tower_2, tower_3, tower_4])\n",
    "    return _layer\n",
    "\n",
    "def Inception_C(filter_size, activation='relu', padding='valid'):\n",
    "    def _layer(input_tensor):\n",
    "        f1, f2 = filter_size // 4, filter_size // 8\n",
    "        \n",
    "        tower_1 = Conv2D(f2, (1, 1), activation=activation, padding=padding)(input_tensor)\n",
    "        tower_1 = Conv2D(f2, (3, 3), activation=activation, padding=padding)(tower_1)\n",
    "        tower_11 = Conv2D(f2, (1, 3), activation=activation, padding=padding)(tower_1)\n",
    "        tower_12 = Conv2D(f2, (3, 1), activation=activation, padding=padding)(tower_1)\n",
    "        \n",
    "        tower_2 = Conv2D(f2, (1, 1), activation=activation, padding=padding)(input_tensor)\n",
    "        tower_21 = Conv2D(f2, (1, 3), activation=activation, padding=padding)(tower_2)\n",
    "        tower_22 = Conv2D(f2, (3, 1), activation=activation, padding=padding)(tower_2)\n",
    "        \n",
    "        tower_3 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(input_tensor)\n",
    "        tower_3 = Conv2D(f1, (1, 1), activation=activation, padding=padding)(tower_3)\n",
    "        \n",
    "        tower_4 = Conv2D(f1, (1, 1), activation=activation, padding=padding)(input_tensor)\n",
    "        \n",
    "        return Concatenate(axis=-1)([tower_11, tower_12, tower_21, tower_22, tower_3, tower_4])\n",
    "        \n",
    "    return _layer\n",
    "\n",
    "def Reduction(filter_size, strides=(2, 2), activation='relu'):\n",
    "    def _layer(input_tensor):\n",
    "        tower_1 = Conv2D(filter_size, (1, 1), activation=activation, padding='same')(input_tensor)\n",
    "        tower_1 = Conv2D(filter_size, (3, 3), activation=activation, padding='same')(tower_1)\n",
    "        tower_1 = Conv2D(filter_size, (3, 3), strides=strides, activation=activation, padding='same')(tower_1)\n",
    "        \n",
    "        tower_2 = Conv2D(filter_size, (1, 1), activation=activation, padding='same')(input_tensor)\n",
    "        tower_2 = Conv2D(filter_size, (3, 3), strides=strides, activation=activation, padding='same')(tower_2)\n",
    "        \n",
    "        tower_3 = MaxPooling2D(pool_size=strides)(input_tensor)\n",
    "        \n",
    "        return Concatenate(axis=-1)([tower_1, tower_2, tower_3])\n",
    "    return _layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_model(input_shape, learning_rate):\n",
    "    inputs = Input(input_shape)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='selu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='selu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    print(\"Pool 1:\", pool1._keras_shape)\n",
    "\n",
    "#     conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "#     conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "#     pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv2 = Inception_B(64, activation='selu', padding='same')(pool1)\n",
    "    print(\"Conv 2:\", conv2._keras_shape)\n",
    "    pool2 = Reduction(16, (2, 2), activation='selu')(conv2)\n",
    "    print(\"Pool 2:\", pool2._keras_shape)\n",
    "\n",
    "#     conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "#     conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "#     pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv3 = Inception_B(128, activation='selu', padding='same')(pool2)\n",
    "    print(\"Conv 3:\", conv3._keras_shape)\n",
    "    pool3 = Reduction(32, (2, 2))(conv3)\n",
    "    print(\"Pool 3:\", pool3._keras_shape)\n",
    "\n",
    "#     conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "#     conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "#     pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    conv4 = Inception_B(256, activation='selu', padding='same')(pool3)\n",
    "    pool4 = Reduction(64, (2, 2))(conv4)\n",
    "    print(\"Pool 4:\", pool4._keras_shape)\n",
    "\n",
    "#     conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "#     conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    conv5 = Inception_C(512, activation='selu', padding='same')(pool4)\n",
    "    print(\"Conv 5:\", conv5._keras_shape)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "#     conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "#     conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "    conv6 = Inception_B(256, activation='selu', padding='same')(up6)\n",
    "    print(\"Conv 6:\", conv6._keras_shape)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "#     conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "#     conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "    conv7 = Inception_B(128, activation='selu', padding='same')(up7)\n",
    "    print(\"Conv 7:\", conv7._keras_shape)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "#     conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "#     conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "    conv8 = Inception_B(64, activation='selu', padding='same')(up8)\n",
    "    print(\"Conv 8:\", conv8._keras_shape)\n",
    "    \n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='selu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='selu', padding='same')(conv9)\n",
    "    print(\"Conv 9:\", conv9._keras_shape)\n",
    "\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "    print(\"Output shape:\", conv10._keras_shape)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "    \n",
    "    model.compile(optimizer=Adam(lr=learning_rate, decay=0.),\n",
    "                  loss=dice_coef_loss,\n",
    "                  metrics=[dice_coef, f1_score, f2_score, f05_score])\n",
    "#     model.compile(optimizer=Adam(lr=learning_rate), loss='cosine', metrics=[dice_coef, f1_score])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pool 1: (None, 48, 64, 32)\n",
      "Conv 2: (None, 48, 64, 64)\n",
      "Pool 2: (None, 24, 32, 96)\n",
      "Conv 3: (None, 24, 32, 128)\n",
      "Pool 3: (None, 12, 16, 192)\n",
      "Pool 4: (None, 6, 8, 384)\n",
      "Conv 5: (None, 6, 8, 512)\n",
      "Conv 6: (None, 12, 16, 256)\n",
      "Conv 7: (None, 24, 32, 128)\n",
      "Conv 8: (None, 48, 64, 64)\n",
      "Conv 9: (None, 96, 128, 32)\n",
      "Output shape: (None, 96, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "model = make_model((IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS), LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1846353"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.count_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-NET Model\n",
    "Parameter count: 7,759,521\n",
    "\n",
    "Pool 1: (None, 48, 64, 32)\n",
    "\n",
    "Pool 2: (None, 24, 32, 64)\n",
    "\n",
    "Pool 3: (None, 12, 16, 128)\n",
    "\n",
    "Pool 4: (None, 6, 8, 256)\n",
    "\n",
    "Conv 5: (None, 6, 8, 512)\n",
    "\n",
    "Conv 6: (None, 12, 16, 256)\n",
    "\n",
    "Conv 8: (None, 48, 64, 64)\n",
    "\n",
    "Conv 8: (None, 48, 64, 64)\n",
    "\n",
    "Output shape: (None, 96, 128, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Archived data set found.\n",
      "... loading data/train_set.npz\n",
      "... loading data/validation_set.npz\n",
      "Pool 1: (None, 48, 64, 32)\n",
      "Conv 2: (None, 48, 64, 64)\n",
      "Pool 2: (None, 24, 32, 96)\n",
      "Conv 3: (None, 24, 32, 128)\n",
      "Pool 3: (None, 12, 16, 192)\n",
      "Pool 4: (None, 6, 8, 384)\n",
      "Conv 5: (None, 6, 8, 512)\n",
      "Conv 6: (None, 12, 16, 256)\n",
      "Conv 7: (None, 24, 32, 128)\n",
      "Conv 8: (None, 48, 64, 64)\n",
      "Conv 9: (None, 96, 128, 32)\n",
      "Output shape: (None, 96, 128, 1)\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 16s - loss: -0.0363 - dice_coef: 0.0363 - f1_score: 0.0361 - val_loss: -0.0460 - val_dice_coef: 0.0460 - val_f1_score: 0.0475\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 7s - loss: -0.0380 - dice_coef: 0.0380 - f1_score: 0.0409 - val_loss: -0.0470 - val_dice_coef: 0.0470 - val_f1_score: 0.0503\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 6s - loss: -0.0381 - dice_coef: 0.0381 - f1_score: 0.0408 - val_loss: -0.0480 - val_dice_coef: 0.0480 - val_f1_score: 0.0527\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 6s - loss: -0.0396 - dice_coef: 0.0396 - f1_score: 0.0432 - val_loss: -0.0489 - val_dice_coef: 0.0489 - val_f1_score: 0.0552\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 6s - loss: -0.0375 - dice_coef: 0.0375 - f1_score: 0.0420 - val_loss: -0.0499 - val_dice_coef: 0.0499 - val_f1_score: 0.0573\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 6s - loss: -0.0403 - dice_coef: 0.0403 - f1_score: 0.0448 - val_loss: -0.0507 - val_dice_coef: 0.0507 - val_f1_score: 0.0595\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 7s - loss: -0.0397 - dice_coef: 0.0397 - f1_score: 0.0459 - val_loss: -0.0516 - val_dice_coef: 0.0516 - val_f1_score: 0.0618\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 6s - loss: -0.0418 - dice_coef: 0.0418 - f1_score: 0.0476 - val_loss: -0.0523 - val_dice_coef: 0.0523 - val_f1_score: 0.0634\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 6s - loss: -0.0424 - dice_coef: 0.0424 - f1_score: 0.0496 - val_loss: -0.0531 - val_dice_coef: 0.0531 - val_f1_score: 0.0646\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 6s - loss: -0.0437 - dice_coef: 0.0437 - f1_score: 0.0508 - val_loss: -0.0538 - val_dice_coef: 0.0538 - val_f1_score: 0.0658\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 6s - loss: -0.0431 - dice_coef: 0.0431 - f1_score: 0.0509 - val_loss: -0.0545 - val_dice_coef: 0.0545 - val_f1_score: 0.0670\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 6s - loss: -0.0435 - dice_coef: 0.0435 - f1_score: 0.0512 - val_loss: -0.0552 - val_dice_coef: 0.0552 - val_f1_score: 0.0681\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 6s - loss: -0.0444 - dice_coef: 0.0444 - f1_score: 0.0525 - val_loss: -0.0560 - val_dice_coef: 0.0560 - val_f1_score: 0.0690\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 6s - loss: -0.0450 - dice_coef: 0.0450 - f1_score: 0.0531 - val_loss: -0.0568 - val_dice_coef: 0.0568 - val_f1_score: 0.0698\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 6s - loss: -0.0463 - dice_coef: 0.0463 - f1_score: 0.0561 - val_loss: -0.0576 - val_dice_coef: 0.0576 - val_f1_score: 0.0704\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 6s - loss: -0.0436 - dice_coef: 0.0436 - f1_score: 0.0522 - val_loss: -0.0583 - val_dice_coef: 0.0583 - val_f1_score: 0.0710\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 6s - loss: -0.0434 - dice_coef: 0.0434 - f1_score: 0.0504 - val_loss: -0.0590 - val_dice_coef: 0.0590 - val_f1_score: 0.0716\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 6s - loss: -0.0449 - dice_coef: 0.0449 - f1_score: 0.0529 - val_loss: -0.0597 - val_dice_coef: 0.0597 - val_f1_score: 0.0723\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 6s - loss: -0.0475 - dice_coef: 0.0475 - f1_score: 0.0555 - val_loss: -0.0603 - val_dice_coef: 0.0603 - val_f1_score: 0.0728\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 7s - loss: -0.0482 - dice_coef: 0.0482 - f1_score: 0.0576 - val_loss: -0.0609 - val_dice_coef: 0.0609 - val_f1_score: 0.0731\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    X_train, y_train, X_val, y_val = get_train_val_sets(TRAIN_SET_PICKLE, VALIDATION_SET_PICKLE)\n",
    "#     X_train, y_train, X_val, y_val = X_train[:16,...], y_train[:16,...], X_val[:16,...], y_val[:16,...]\n",
    "    model = make_model((IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS), LEARNING_RATE)\n",
    "    model_checkpoint = ModelCheckpoint(WEIGHTS_FILE, monitor='val_loss', save_best_only=True)\n",
    "    train_monitor = TrainMonitor(HISTORY_LOG, X_train[:1,...], y_train[:1,...], out_dir=\"output/preds/\")\n",
    "    \n",
    "    return model.fit_generator(image_augment(X_train, y_train, batch_size=TRAIN_BATCH_SIZE, seed=10), \n",
    "                        y_train.shape[0] // TRAIN_BATCH_SIZE,\n",
    "                        epochs=EPOCHS_TO_RUN,\n",
    "                        verbose=1,\n",
    "                        callbacks=[model_checkpoint, train_monitor], \n",
    "                        validation_data=(X_val, y_val))\n",
    "hist = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(X, batch_size=8):\n",
    "    model = load_model(WEIGHTS_FILE, verbose=1,\n",
    "                       custom_objects={'dice_coef_loss': dice_coef_loss, \n",
    "                                       'dice_coef': dice_coef,\n",
    "                                       'f1_score': f1_score})\n",
    "    return model.predict(X, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
